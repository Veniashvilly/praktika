{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5cfab25",
   "metadata": {},
   "source": [
    "**Домашнее задание к уроку 2: Линейная и логистическая регрессия**\\\n",
    "**Цель задания**\\\n",
    "**Закрепить навыки работы с PyTorch API, изучить модификацию моделей и работу с различными датасетами.**\\\n",
    "**Задание 1: Модификация существующих моделей (30 баллов)**\\\n",
    "**1.1 Расширение линейной регрессии (15 баллов)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ccb542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: 200\n",
      "Количество батчей: 7\n",
      "Epoch 10: loss=0.0370\n",
      "Epoch 20: loss=0.0155\n",
      "Epoch 30: loss=0.0112\n",
      "Epoch 40: loss=0.0113\n",
      "Epoch 50: loss=0.0108\n",
      "Epoch 60: loss=0.0125\n",
      "Epoch 70: loss=0.0104\n",
      "Остановка перед переобучением\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import make_regression_data, mse, log_epoch, RegressionDataset\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Генерируем данные\n",
    "    X, y = make_regression_data(n=200)\n",
    "    \n",
    "    # Создаём датасет и даталоадер\n",
    "    dataset = RegressionDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    print(f'Размер датасета: {len(dataset)}')\n",
    "    print(f'Количество батчей: {len(dataloader)}')\n",
    "    \n",
    "    # Создаём модель, функцию потерь и оптимизатор\n",
    "    model = LinearRegression(in_features=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    reg_type = 'l2'  # или 'l1', или None\n",
    "    alpha = 0.0001    # Коэффициент регуляризации\n",
    "\n",
    "    d = 0.0001 #коэфицент остановки\n",
    "    prev_weights = [w.detach().clone() for w in model.linear.weight] #сохраняем веса \n",
    "\n",
    "    # Обучаем модель\n",
    "    epochs = 100\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "            reg = 0\n",
    "            if reg_type == 'l1':\n",
    "                reg = alpha * model.linear.weight.abs().sum() #l1\n",
    "            elif reg_type == 'l2':\n",
    "                reg = alpha * (model.linear.weight ** 2).sum() #l2\n",
    "            loss = criterion(y_pred, batch_y) + reg #штраф\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        weight_change = ((model.linear.weight - prev_weights[0]) ** 2).sum().sqrt().item() #проверка разницы весов с прошлой итерацией\n",
    "        if weight_change < d:\n",
    "            print(f\"Остановка перед переобучением\")\n",
    "            break\n",
    "        prev_weights = [w.detach().clone() for w in model.linear.weight] #сохраняем веса итерации\n",
    "\n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, avg_loss)\n",
    "\n",
    "    # Сохраняем модель\n",
    "    torch.save(model.state_dict(), 'linreg_torch.pth')\n",
    "    \n",
    "    # Загружаем модель\n",
    "    new_model = LinearRegression(in_features=1)\n",
    "    new_model.load_state_dict(torch.load('linreg_torch.pth'))\n",
    "    new_model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e921f",
   "metadata": {},
   "source": [
    "**1.2 Расширение логистической регрессии (15 баллов)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8374b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: 200\n",
      "Количество батчей: 7\n",
      "Epoch 10: loss=0.6445, acc=0.7500\n",
      "Precision: 0.6667, Recall: 0.5833, F1: 0.6190, ROC-AUC: nan\n",
      "Epoch 20: loss=0.6381, acc=0.7188\n",
      "Precision: 0.8056, Recall: 0.7778, F1: 0.7190, ROC-AUC: 0.8389\n",
      "Epoch 30: loss=0.6704, acc=0.7098\n",
      "Precision: 0.5556, Recall: 0.5000, F1: 0.5238, ROC-AUC: 0.8006\n",
      "Epoch 40: loss=0.6662, acc=0.7143\n",
      "Precision: 0.2778, Recall: 0.2778, F1: 0.2778, ROC-AUC: nan\n",
      "Epoch 50: loss=0.6001, acc=0.7545\n",
      "Precision: 0.9333, Recall: 0.8889, F1: 0.8963, ROC-AUC: 1.0000\n",
      "Epoch 60: loss=0.6309, acc=0.7411\n",
      "Precision: 0.7667, Recall: 0.7778, F1: 0.6852, ROC-AUC: 0.8190\n",
      "Epoch 70: loss=0.6353, acc=0.7143\n",
      "Precision: 0.6333, Recall: 0.5000, F1: 0.5000, ROC-AUC: 0.8278\n",
      "Epoch 80: loss=0.6002, acc=0.7455\n",
      "Precision: 0.9167, Recall: 0.9167, F1: 0.9048, ROC-AUC: 1.0000\n",
      "Epoch 90: loss=0.6171, acc=0.7545\n",
      "Precision: 0.9167, Recall: 0.8889, F1: 0.8857, ROC-AUC: 0.8889\n",
      "Epoch 100: loss=0.6305, acc=0.7366\n",
      "Precision: 0.7333, Recall: 0.7333, F1: 0.7333, ROC-AUC: nan\n",
      "\n",
      "Confusion Matrix:\n",
      "Pred →      0       1       2\n",
      "True   0     62      5      0\n",
      "True   1     10     39     18\n",
      "True   2      6     14     46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import make_classification_data, accuracy, log_epoch, ClassificationDataset, metrics\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_features,num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, num_classes) #добавили многоклассовость\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Генерируем данные\n",
    "    num_classes = 3\n",
    "    X, y = make_classification_data(n=200, num_classes=num_classes) #подаем колво классов\n",
    "    \n",
    "    # Создаём датасет и даталоадер\n",
    "    dataset = ClassificationDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    print(f'Размер датасета: {len(dataset)}')\n",
    "    print(f'Количество батчей: {len(dataloader)}')\n",
    "    \n",
    "    # Создаём модель, функцию потерь и оптимизатор\n",
    "    model = LogisticRegression(in_features=X.shape[1], num_classes=num_classes) #изменили модель\n",
    "    criterion = nn.CrossEntropyLoss() #поменяли loss функцию для многоклассовой\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    # Обучаем модель\n",
    "    epochs = 100\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_X)\n",
    "\n",
    "            y_probs = torch.softmax(logits, dim=1) # Преобразуем логиты в вероятности\n",
    "            y_pred = y_probs.argmax(dim=1) # Получаем предсказанные классы\n",
    "            all_preds.extend(y_pred.detach().cpu().numpy()) # Сохраняем предсказания для всей эпохи\n",
    "            all_true.extend(batch_y.detach().cpu().numpy()) # Сохраняем истинные метки для всей эпохи\n",
    "\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Вычисляем accuracy\n",
    "            y_pred = logits\n",
    "            acc = accuracy(y_pred, batch_y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "        \n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        avg_acc = total_acc / (i + 1)\n",
    "        \n",
    "        precision, recall, f1, roc_auc = metrics(logits, batch_y) #нахождение метрик\n",
    "\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, avg_loss, acc=avg_acc)\n",
    "            print(\n",
    "            f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Визуализация confusion matrix\n",
    "    cm = confusion_matrix(all_true, all_preds)  # Вычисление confusion matrix\n",
    "\n",
    "    num_classes = cm.shape[0]\n",
    "    class_names = [f\"{i}\" for i in range(num_classes)]\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    header = \"Pred → \" + \"  \".join([f\"{name:>6}\" for name in class_names])\n",
    "    print(header)\n",
    "    for i, row in enumerate(cm):\n",
    "        row_str = \" \".join([f\"{val:>6}\" for val in row])\n",
    "        print(f\"True {class_names[i]:>3} {row_str}\")\n",
    "    \n",
    "    # Сохраняем модель\n",
    "    torch.save(model.state_dict(), 'logreg_torch.pth')\n",
    "    \n",
    "    # Загружаем модель\n",
    "    new_model = LogisticRegression(in_features=X.shape[1], num_classes=num_classes)\n",
    "    new_model.load_state_dict(torch.load('logreg_torch.pth'))\n",
    "    new_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
